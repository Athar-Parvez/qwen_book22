---
sidebar_position: 1
---

# Vision-Language-Action (VLA)

## Understanding Vision-Language-Action Models

Vision-Language-Action (VLA) models represent a breakthrough in robotics, enabling robots to understand natural language instructions and execute corresponding physical actions in the real world.

## Key Capabilities

- **Multimodal Understanding**: Integrating visual, textual, and action spaces
- **Task Generalization**: Performing novel tasks from natural language descriptions
- **Real-World Manipulation**: Converting abstract commands into specific robot actions